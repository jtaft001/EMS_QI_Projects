{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-09T17:11:28.888762Z",
     "start_time": "2025-06-09T17:11:19.762078Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from IPython.display import display\n",
    "\n",
    "# === DB Connection ===\n",
    "engine = create_engine(\"postgresql://jtaft:GunnersMate2003!@100.118.151.104:5432/datalake\")\n",
    "\n",
    "# === Load Data from Cleaned Table ===\n",
    "print(\"ðŸ“¥ Loading data from PostgreSQL (ahaems_cleaned)...\")\n",
    "df = pd.read_sql(\"SELECT * FROM ahaems_cleaned\", con=engine)\n",
    "\n",
    "# === Rename for internal use ===\n",
    "df = df.rename(columns={\n",
    "    \"UniqueIncidentKey\": \"incident_id\",\n",
    "    \"Patient Age (ePatient.15)\": \"age\",\n",
    "    \"Patient Age Units (ePatient.16)\": \"age_units\",\n",
    "    \"Primary Impression\": \"primary_impression\",\n",
    "    \"Secondary Impression\": \"secondary_impression\",\n",
    "    \"Transport Disposition\": \"transport_disposition\",\n",
    "    \"Response Type Of Service Requested With Code (eResponse.05)\": \"response_type\",\n",
    "    \"Situation Last Known Well Date Time (eSituation.18)\": \"lkw_time\",\n",
    "    \"Vitals Signs Taken Date Time (eVitals.01)\": \"vitals_time\",\n",
    "    \"Patient Cincinnati Stroke Scale Used (eVitals.30)\": \"stroke_scale_type\",\n",
    "    \"Patient Initial Stroke Scale Score (eVitals.29)\": \"stroke_scale_score\",\n",
    "    \"Cardiac Arrest During EMS Event With Code (eArrest.01)\": \"cardiac_arrest\",\n",
    "    \"Disposition Final Patient Acuity Code (eDisposition.19)\": \"final_acuity\"\n",
    "})\n",
    "\n",
    "# === Convert datetime fields ===\n",
    "df[\"lkw_time\"] = pd.to_datetime(df[\"lkw_time\"], format=\"%m/%d/%Y %I:%M:%S %p\", errors=\"coerce\")\n",
    "df[\"vitals_time\"] = pd.to_datetime(df[\"vitals_time\"], format=\"%m/%d/%Y %I:%M:%S %p\", errors=\"coerce\")\n",
    "\n",
    "# === Extract ICDs ===\n",
    "def extract_icd_prefix(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.search(r\"\\(([A-Z]\\d{2}(?:\\.\\d+)?)\\)\", text.upper())\n",
    "        if match:\n",
    "            return match.group(1)[:3]\n",
    "    return \"\"\n",
    "\n",
    "df[\"primary_icd\"] = df[\"primary_impression\"].apply(extract_icd_prefix)\n",
    "df[\"secondary_icd\"] = df[\"secondary_impression\"].apply(extract_icd_prefix)\n",
    "\n",
    "# === Aggregate to 1 row per incident ===\n",
    "grouped = df.groupby(\"incident_id\").agg({\n",
    "    \"age\": \"first\",\n",
    "    \"age_units\": \"first\",\n",
    "    \"primary_icd\": \"first\",\n",
    "    \"secondary_icd\": \"first\",\n",
    "    \"transport_disposition\": \"first\",\n",
    "    \"response_type\": \"first\",\n",
    "    \"vitals_time\": \"min\",\n",
    "    \"lkw_time\": \"first\",\n",
    "    \"stroke_scale_type\": \"first\",\n",
    "    \"stroke_scale_score\": \"first\",\n",
    "    \"cardiac_arrest\": \"first\",\n",
    "    \"final_acuity\": \"first\"\n",
    "}).reset_index()\n",
    "\n",
    "# === Quarter Extraction ===\n",
    "grouped[\"quarter\"] = grouped[\"vitals_time\"].dt.to_period(\"Q\")\n",
    "\n",
    "# === Denominator Logic ===\n",
    "grouped[\"age\"] = pd.to_numeric(grouped[\"age\"], errors=\"coerce\")\n",
    "age_valid = (grouped[\"age\"] >= 18) & (grouped[\"age_units\"].str.lower() == \"years\")\n",
    "stroke_icds = [\"I60\", \"I61\", \"I63\", \"G45\", \"G46\"]\n",
    "impression_valid = grouped[\"primary_icd\"].isin(stroke_icds) | grouped[\"secondary_icd\"].isin(stroke_icds)\n",
    "transport_valid = grouped[\"transport_disposition\"].str.contains(\"transport by\", case=False, na=False)\n",
    "response_valid = grouped[\"response_type\"].str.contains(\"2205001|2205003|2205009\", na=False)\n",
    "\n",
    "# Exclusions\n",
    "exclude_lkw = (\n",
    "    grouped[\"lkw_time\"].notna() & grouped[\"vitals_time\"].notna() &\n",
    "    ((grouped[\"vitals_time\"] - grouped[\"lkw_time\"]).dt.total_seconds() >= 86400)\n",
    ")\n",
    "exclude_arrest = grouped[\"cardiac_arrest\"].astype(str).isin([\"3001003\", \"3001005\"])\n",
    "exclude_acuity = grouped[\"final_acuity\"].astype(str) == \"4219909\"\n",
    "\n",
    "grouped[\"in_denominator\"] = (\n",
    "    age_valid & impression_valid & transport_valid & response_valid &\n",
    "    ~exclude_lkw & ~exclude_arrest & ~exclude_acuity\n",
    ")\n",
    "\n",
    "# === Numerator Logic ===\n",
    "valid_stroke_scales = [\n",
    "    \"3330001\", \"3330004\", \"3330005\", \"3330007\", \"3330009\", \"3330011\",\n",
    "    \"3330013\", \"3330015\", \"3330017\", \"3330019\", \"3330021\", \"3330023\"\n",
    "]\n",
    "valid_stroke_scores = [\n",
    "    \"3329001\", \"3329003\", \"3329005\", \"8801019\", \"8801023\"\n",
    "]\n",
    "\n",
    "grouped[\"in_numerator\"] = (\n",
    "    grouped[\"in_denominator\"] &\n",
    "    grouped[\"stroke_scale_type\"].astype(str).isin(valid_stroke_scales) &\n",
    "    grouped[\"stroke_scale_score\"].astype(str).isin(valid_stroke_scores)\n",
    ")\n",
    "\n",
    "# === Summary Output ===\n",
    "summary = (\n",
    "    grouped[grouped[\"in_denominator\"]]\n",
    "    .groupby(\"quarter\")\n",
    "    .agg(\n",
    "        AHAEMS4_Denominator=(\"in_denominator\", \"sum\"),\n",
    "        AHAEMS4_Numerator=(\"in_numerator\", \"sum\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "summary[\"AHAEMS4_Percentage\"] = (summary[\"AHAEMS4_Numerator\"] / summary[\"AHAEMS4_Denominator\"] * 100).round(2)\n",
    "display(summary)\n",
    "\n",
    "# === Export Fallout CSV ===\n",
    "fallouts = grouped[grouped[\"in_denominator\"] & ~grouped[\"in_numerator\"]]\n",
    "fallout_path = \"/Volumes/jupyter/EMS_QI_Projects/ahaems-2025-submission/output/fallouts/ahaems4_fallouts.csv\"\n",
    "os.makedirs(os.path.dirname(fallout_path), exist_ok=True)\n",
    "fallouts.to_csv(fallout_path, index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading data from PostgreSQL (ahaems_cleaned)...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['stroke_scale_score'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     44\u001B[39m df[\u001B[33m\"\u001B[39m\u001B[33msecondary_icd\u001B[39m\u001B[33m\"\u001B[39m] = df[\u001B[33m\"\u001B[39m\u001B[33msecondary_impression\u001B[39m\u001B[33m\"\u001B[39m].apply(extract_icd_prefix)\n\u001B[32m     46\u001B[39m \u001B[38;5;66;03m# === Aggregate to 1 row per incident ===\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m grouped = \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mincident_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mage\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mage_units\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprimary_icd\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     51\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msecondary_icd\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtransport_disposition\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_type\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvitals_time\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmin\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlkw_time\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstroke_scale_type\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstroke_scale_score\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcardiac_arrest\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfinal_acuity\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfirst\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     60\u001B[39m \u001B[43m}\u001B[49m\u001B[43m)\u001B[49m.reset_index()\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# === Quarter Extraction ===\u001B[39;00m\n\u001B[32m     63\u001B[39m grouped[\u001B[33m\"\u001B[39m\u001B[33mquarter\u001B[39m\u001B[33m\"\u001B[39m] = grouped[\u001B[33m\"\u001B[39m\u001B[33mvitals_time\u001B[39m\u001B[33m\"\u001B[39m].dt.to_period(\u001B[33m\"\u001B[39m\u001B[33mQ\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/groupby/generic.py:1432\u001B[39m, in \u001B[36mDataFrameGroupBy.aggregate\u001B[39m\u001B[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[39m\n\u001B[32m   1429\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m] = engine_kwargs\n\u001B[32m   1431\u001B[39m op = GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args=args, kwargs=kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1432\u001B[39m result = \u001B[43mop\u001B[49m\u001B[43m.\u001B[49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1433\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1434\u001B[39m     \u001B[38;5;66;03m# GH #52849\u001B[39;00m\n\u001B[32m   1435\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.as_index \u001B[38;5;129;01mand\u001B[39;00m is_list_like(func):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/apply.py:190\u001B[39m, in \u001B[36mApply.agg\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_str()\n\u001B[32m    189\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_dict_like(func):\n\u001B[32m--> \u001B[39m\u001B[32m190\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43magg_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(func):\n\u001B[32m    192\u001B[39m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[32m    193\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.agg_list_like()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/apply.py:423\u001B[39m, in \u001B[36mApply.agg_dict_like\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34magg_dict_like\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> DataFrame | Series:\n\u001B[32m    416\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    417\u001B[39m \u001B[33;03m    Compute aggregation in the case of a dict-like argument.\u001B[39;00m\n\u001B[32m    418\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    421\u001B[39m \u001B[33;03m    Result of aggregation.\u001B[39;00m\n\u001B[32m    422\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43magg_or_apply_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43magg\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/apply.py:1608\u001B[39m, in \u001B[36mGroupByApply.agg_or_apply_dict_like\u001B[39m\u001B[34m(self, op_name)\u001B[39m\n\u001B[32m   1603\u001B[39m     kwargs.update({\u001B[33m\"\u001B[39m\u001B[33mengine\u001B[39m\u001B[33m\"\u001B[39m: engine, \u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m: engine_kwargs})\n\u001B[32m   1605\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m com.temp_setattr(\n\u001B[32m   1606\u001B[39m     obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, condition=\u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1607\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1608\u001B[39m     result_index, result_data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_dict_like\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1609\u001B[39m \u001B[43m        \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1610\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1611\u001B[39m result = \u001B[38;5;28mself\u001B[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001B[32m   1612\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/apply.py:462\u001B[39m, in \u001B[36mApply.compute_dict_like\u001B[39m\u001B[34m(self, op_name, selected_obj, selection, kwargs)\u001B[39m\n\u001B[32m    460\u001B[39m is_groupby = \u001B[38;5;28misinstance\u001B[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001B[32m    461\u001B[39m func = cast(AggFuncTypeDict, \u001B[38;5;28mself\u001B[39m.func)\n\u001B[32m--> \u001B[39m\u001B[32m462\u001B[39m func = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnormalize_dictlike_arg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    464\u001B[39m is_non_unique_col = (\n\u001B[32m    465\u001B[39m     selected_obj.ndim == \u001B[32m2\u001B[39m\n\u001B[32m    466\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m selected_obj.columns.nunique() < \u001B[38;5;28mlen\u001B[39m(selected_obj.columns)\n\u001B[32m    467\u001B[39m )\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m selected_obj.ndim == \u001B[32m1\u001B[39m:\n\u001B[32m    470\u001B[39m     \u001B[38;5;66;03m# key only used for output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/apply.py:663\u001B[39m, in \u001B[36mApply.normalize_dictlike_arg\u001B[39m\u001B[34m(self, how, obj, func)\u001B[39m\n\u001B[32m    661\u001B[39m     cols = Index(\u001B[38;5;28mlist\u001B[39m(func.keys())).difference(obj.columns, sort=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    662\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cols) > \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m663\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mColumn(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(cols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m do not exist\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    665\u001B[39m aggregator_types = (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m    667\u001B[39m \u001B[38;5;66;03m# if we have a dict of any non-scalars\u001B[39;00m\n\u001B[32m    668\u001B[39m \u001B[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001B[39;00m\n\u001B[32m    669\u001B[39m \u001B[38;5;66;03m# be list-likes\u001B[39;00m\n\u001B[32m    670\u001B[39m \u001B[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001B[39;00m\n",
      "\u001B[31mKeyError\u001B[39m: \"Column(s) ['stroke_scale_score'] do not exist\""
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca05e884d2d72626"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
